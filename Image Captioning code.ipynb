{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "151af5e1",
   "metadata": {},
   "source": [
    "# Building an AI-Powered Image Captioning GUI with Tkinter and Hugging Face Transformers\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7fa2b4",
   "metadata": {},
   "source": [
    "Importing the necessary modules to build a graphical user interface (GUI) that allows users to select images and generate captions using a pre-trained model from Hugging Faceâ€™s **Transformers** library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e72b532d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navbc\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# Import Tkinter for creating the graphical user interface (GUI)\n",
    "import tkinter as tk\n",
    "\n",
    "# Import specific Tkinter components for file selection, labels, buttons, frames, canvas, and scrollbars\n",
    "from tkinter import filedialog, Label, Button, Frame, Canvas, Scrollbar\n",
    "\n",
    "# Import Image and ImageTk from Pillow for image processing and compatibility with Tkinter\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Import BLIP processor and model from Hugging Face Transformers for image captioning\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a2d070",
   "metadata": {},
   "source": [
    "### Initialize the processor and model from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af4eab34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navbc\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n"
     ]
    }
   ],
   "source": [
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\") # Load the BLIP processor to prepare image data for the model\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\") # Load the pre-trained BLIP model for generating image captions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4f8fb5",
   "metadata": {},
   "source": [
    "### Function to generate caption for a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17c91467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption(image_path):\n",
    "\n",
    "    image = Image.open(image_path)    \n",
    "    # Process the image to convert it into model-compatible inputs\n",
    "    inputs = processor(image, return_tensors=\"pt\")\n",
    "    # Generate a caption for the image with a maximum of 50 tokens\n",
    "    outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "    # Decode the model output into a readable caption text\n",
    "    caption = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return caption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f55686",
   "metadata": {},
   "source": [
    "### Function to select images and display captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5802b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_images():\n",
    "    # Clear previous images and captions\n",
    "    for widget in image_frame.winfo_children():\n",
    "        widget.destroy()\n",
    "\n",
    "    # Open file dialog to select multiple images\n",
    "    file_paths = filedialog.askopenfilenames(filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png *.bmp\")])\n",
    "    \n",
    "    # Define grid layout\n",
    "    max_columns = 3  # Number of images per row\n",
    "    row = 0\n",
    "    col = 0\n",
    "\n",
    "    # Process each selected image\n",
    "    for file_path in file_paths:\n",
    "        # Generate caption for the image\n",
    "        caption = generate_caption(file_path)\n",
    "        \n",
    "        # Open the image and resize it for display\n",
    "        img = Image.open(file_path)\n",
    "        img.thumbnail((200, 200))  # Resize for display in the GUI\n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "\n",
    "        # Display image and caption in the GUI\n",
    "        img_label = Label(image_frame, image=img_tk, bg=\"white\")\n",
    "        img_label.image = img_tk  # Keep a reference to avoid garbage collection\n",
    "        img_label.grid(row=row, column=col, padx=10, pady=10)\n",
    "\n",
    "        caption_label = Label(image_frame, text=caption, wraplength=200, justify=\"center\",\n",
    "                              bg=\"white\", fg=\"black\", font=(\"Helvetica\", 10, \"italic\"))\n",
    "        caption_label.grid(row=row + 1, column=col, padx=10, pady=5)\n",
    "\n",
    "        # Update column and row counters\n",
    "        col += 1\n",
    "        if col >= max_columns:\n",
    "            col = 0\n",
    "            row += 2  # Move to the next row after filling columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea45ab9f",
   "metadata": {},
   "source": [
    "### Create the main GUI window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c86015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "root.title(\"Image Caption Generator\")\n",
    "root.geometry(\"600x600\")\n",
    "root.configure(bg=\"white\")  # Set the main background color to white\n",
    "\n",
    "# Instructions label\n",
    "instruction_label = Label(root, text=\"Select multiple images to generate captions\",\n",
    "                          font=(\"Arial\", 14), fg=\"black\", bg=\"white\")\n",
    "instruction_label.pack(pady=10)\n",
    "\n",
    "# Button to select images\n",
    "select_button = Button(root, text=\"Select Images\", command=select_images,\n",
    "                       font=(\"Arial\", 12), bg=\"lightgray\", fg=\"black\", activebackground=\"darkgray\")\n",
    "select_button.pack(pady=20)\n",
    "\n",
    "# Create a canvas and scrollbar for the image_frame to make it scrollable\n",
    "canvas = Canvas(root, bg=\"white\", width=580, height=400)\n",
    "canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "\n",
    "scrollbar = Scrollbar(root, orient=\"vertical\", command=canvas.yview)\n",
    "scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "\n",
    "canvas.configure(yscrollcommand=scrollbar.set)\n",
    "\n",
    "# Create a frame inside the canvas\n",
    "image_frame = Frame(canvas, bg=\"white\")\n",
    "\n",
    "# Bind the frame to the canvas and add it to the canvas window\n",
    "canvas.create_window((0, 0), window=image_frame, anchor=\"nw\")\n",
    "\n",
    "# Update the scroll region of the canvas whenever the frame's size changes\n",
    "def update_scroll_region(event):\n",
    "    canvas.configure(scrollregion=canvas.bbox(\"all\"))\n",
    "\n",
    "image_frame.bind(\"<Configure>\", update_scroll_region)\n",
    "\n",
    "# Run the GUI\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8556a9",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
